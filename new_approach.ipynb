{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dense, Flatten, Dropout, Input\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load seismic data from the CSV file\n",
    "def load_seismic_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data\n",
    "\n",
    "# Preprocess the velocity data\n",
    "def preprocess_data(velocity_data):\n",
    "    # 1. Normalize the velocity data (zero mean, unit variance)\n",
    "    normalized_data = (velocity_data - np.mean(velocity_data)) / np.std(velocity_data)\n",
    "    \n",
    "    # 2. Reshape to add the feature dimension (required by Conv1D)\n",
    "    reshaped_data = np.expand_dims(normalized_data, axis=-1)  # Shape: (timesteps, 1 feature)\n",
    "    # print(normalized_data.shape, reshaped_data.shape)\n",
    "    \n",
    "    return reshaped_data\n",
    "\n",
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Use the Input layer explicitly\n",
    "    model.add(Input(shape=input_shape))\n",
    "    \n",
    "    # Then proceed with the rest of the layers\n",
    "    model.add(Conv1D(32, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(64, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Binary classification (quake start or not)\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Load and process the catalog\n",
    "cat_directory = './data/lunar/training/catalogs/'\n",
    "cat_file = cat_directory + 'apollo12_catalog_GradeA_final.csv'\n",
    "cat = pd.read_csv(cat_file)\n",
    "\n",
    "# Prepare training data (seismic data + labels for quake start detection)\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "# Define a max length for padding/truncating\n",
    "MAX_TIMESTEPS = 60000  # You can adjust this based on your data\n",
    "\n",
    "# Loop through the catalog\n",
    "for i, (file_name, _, start_time, _, quake_type) in cat.iterrows():\n",
    "    file_path = f\"./data/lunar/training/data/S12_GradeA/{file_name}.csv\"\n",
    "    if not os.path.isfile(file_path):\n",
    "        continue\n",
    "\n",
    "    # Load seismic data\n",
    "    data_chunk = load_seismic_data(file_path)\n",
    "    velocity = data_chunk['velocity(m/s)'].values\n",
    "    time = data_chunk['time_rel(sec)'].values\n",
    "\n",
    "    # Preprocess velocity data\n",
    "    processed_velocity = preprocess_data(velocity)  # Shape: (timesteps, 1 feature)\n",
    "\n",
    "    # Labeling: Create a binary label for detecting quake start\n",
    "    start_index = np.argmin(np.abs(time - start_time))  # Closest index to the start time\n",
    "    labels = np.zeros(len(time))\n",
    "    labels[start_index] = 1  # Label the start of the moonquake\n",
    "\n",
    "    # Append processed data and labels to training set\n",
    "    X_train.append(processed_velocity)\n",
    "    y_train.append(labels)\n",
    "\n",
    "# Convert lists to numpy arrays with consistent time series length using padding\n",
    "X_train_padded = pad_sequences(X_train, maxlen=MAX_TIMESTEPS, dtype='float32', padding='post', truncating='post')\n",
    "y_train_padded = pad_sequences(y_train, maxlen=MAX_TIMESTEPS, dtype='float32', padding='post', truncating='post')\n",
    "\n",
    "# Convert lists to numpy arrays for model training\n",
    "X_train = np.array(X_train_padded)\n",
    "y_train = np.array(y_train_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (75, 60000, 1)\n",
      "y_train shape: (75, 60000)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of X_train and y_train\n",
    "print(\"X_train shape:\", X_train.shape)  # DEBUGGING STEP\n",
    "print(\"y_train shape:\", y_train.shape)  # DEBUGGING STEP\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the model\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])  # Shape: (timesteps, features)\n",
    "model = build_model(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 60000), output.shape=(None, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_val, y_val), verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/GitHub/debugging-the-universe/seismic_venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[39m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Documents/GitHub/debugging-the-universe/seismic_venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/nn.py:701\u001b[0m, in \u001b[0;36mbinary_crossentropy\u001b[0;34m(target, output, from_logits)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[39mfor\u001b[39;00m e1, e2 \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(target\u001b[39m.\u001b[39mshape, output\u001b[39m.\u001b[39mshape):\n\u001b[1;32m    700\u001b[0m     \u001b[39mif\u001b[39;00m e1 \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m e2 \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m e1 \u001b[39m!=\u001b[39m e2:\n\u001b[0;32m--> 701\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    702\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mArguments `target` and `output` must have the same shape. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    703\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReceived: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    704\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtarget.shape=\u001b[39m\u001b[39m{\u001b[39;00mtarget\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m, output.shape=\u001b[39m\u001b[39m{\u001b[39;00moutput\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    707\u001b[0m output, from_logits \u001b[39m=\u001b[39m _get_logits(\n\u001b[1;32m    708\u001b[0m     output, from_logits, \u001b[39m\"\u001b[39m\u001b[39mSigmoid\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    709\u001b[0m )\n\u001b[1;32m    711\u001b[0m \u001b[39mif\u001b[39;00m from_logits:\n",
      "\u001b[0;31mValueError\u001b[0m: Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 60000), output.shape=(None, 1)"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Predict moonquake start on new data\n",
    "def predict_moonquake_start(file_path):\n",
    "    data_chunk = load_seismic_data(file_path)\n",
    "    velocity = data_chunk['velocity(m/s)'].values\n",
    "    processed_velocity = preprocess_data(velocity)\n",
    "    processed_velocity = np.expand_dims(processed_velocity, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Make prediction\n",
    "    predictions = model.predict(processed_velocity)\n",
    "    start_time_index = np.argmax(predictions)  # Get the index with the highest prediction\n",
    "    start_time = data_chunk['time_rel(sec)'].values[start_time_index]\n",
    "\n",
    "    return start_time\n",
    "\n",
    "# Example prediction on new test data\n",
    "test_file_path = \"./data/lunar/test/S12_GradeA/test_file.csv\"\n",
    "predicted_start_time = predict_moonquake_start(test_file_path)\n",
    "print(f\"Predicted Moonquake Start Time: {predicted_start_time}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismic_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
